{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habrev/Rossmann-Pharmaceuticals/blob/task-2/notebooks/prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KLfVBtbeB7G"
      },
      "source": [
        "# Dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tM4kCfMMeB7I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPpKUedqeB7J"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "434o9yLBeB7J"
      },
      "source": [
        "# file imported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YPyzghdbeB7K"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# one-hot-encoding for numerical columns"
      ],
      "metadata": {
        "id": "IAlF684yl0H4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxjK4Vg5eB7L",
        "outputId": "f1b1f351-b3ce-48a5-c8cb-65dff8349945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
            "0   1      1          4  2015-09-17   1.0      1            0              0\n",
            "1   2      3          4  2015-09-17   1.0      1            0              0\n",
            "2   3      7          4  2015-09-17   1.0      1            0              0\n",
            "3   4      8          4  2015-09-17   1.0      1            0              0\n",
            "4   5      9          4  2015-09-17   1.0      1            0              0\n",
            "\n",
            "Encoded file saved to one_hot_encoded_test.csv\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Original Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Identify non-numerical columns\n",
        "non_numerical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Convert all non-numerical columns to strings (if necessary)\n",
        "df[non_numerical_columns] = df[non_numerical_columns].astype(str)\n",
        "\n",
        "# Perform One-Hot Encoding on all non-numerical columns\n",
        "df_encoded = pd.get_dummies(df, columns=non_numerical_columns)\n",
        "\n",
        "# Optionally, save the encoded data to a new file\n",
        "output_path = 'one_hot_encoded_test.csv'\n",
        "df_encoded.to_csv(output_path, index=False)\n",
        "print(f\"\\nEncoded file saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H83bYeWeeB7M"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('one_hot_encoded_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Identify numerical columns to scale\n",
        "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale the numerical columns\n",
        "df_scaled = df.copy()\n",
        "df_scaled[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Save the scaled dataset\n",
        "scaled_output_path = 'scaled_dataset_test.csv'\n",
        "df_scaled.to_csv(scaled_output_path, index=False)\n",
        "\n",
        "# Display a preview of the scaled DataFrame\n",
        "print(f\"Scaled Data saved to {scaled_output_path}\")\n",
        "print(df_scaled.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opq9Eg4YX6ep",
        "outputId": "b69fafd8-a732-4fcc-a6eb-58875bef4334"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled Data saved to scaled_dataset_test.csv\n",
            "         Id     Store  DayOfWeek      Open     Promo  SchoolHoliday  \\\n",
            "0 -1.732009 -1.732596   0.010337  0.412939  1.235442      -0.892695   \n",
            "1 -1.731924 -1.726351   0.010337  0.412939  1.235442      -0.892695   \n",
            "2 -1.731840 -1.713862   0.010337  0.412939  1.235442      -0.892695   \n",
            "3 -1.731756 -1.710739   0.010337  0.412939  1.235442      -0.892695   \n",
            "4 -1.731671 -1.707617   0.010337  0.412939  1.235442      -0.892695   \n",
            "\n",
            "   Date_2015-08-01  Date_2015-08-02  Date_2015-08-03  Date_2015-08-04  ...  \\\n",
            "0            False            False            False            False  ...   \n",
            "1            False            False            False            False  ...   \n",
            "2            False            False            False            False  ...   \n",
            "3            False            False            False            False  ...   \n",
            "4            False            False            False            False  ...   \n",
            "\n",
            "   Date_2015-09-10  Date_2015-09-11  Date_2015-09-12  Date_2015-09-13  \\\n",
            "0            False            False            False            False   \n",
            "1            False            False            False            False   \n",
            "2            False            False            False            False   \n",
            "3            False            False            False            False   \n",
            "4            False            False            False            False   \n",
            "\n",
            "   Date_2015-09-14  Date_2015-09-15  Date_2015-09-16  Date_2015-09-17  \\\n",
            "0            False            False            False             True   \n",
            "1            False            False            False             True   \n",
            "2            False            False            False             True   \n",
            "3            False            False            False             True   \n",
            "4            False            False            False             True   \n",
            "\n",
            "   StateHoliday_0  StateHoliday_a  \n",
            "0            True           False  \n",
            "1            True           False  \n",
            "2            True           False  \n",
            "3            True           False  \n",
            "4            True           False  \n",
            "\n",
            "[5 rows x 56 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model building with sklearn pipelines"
      ],
      "metadata": {
        "id": "BGstHg30l8yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"scaled_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Define target and feature columns\n",
        "target = 'Sales'  # Target column\n",
        "features = [col for col in df.columns if col != target]  # All columns except the target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Scale the features\n",
        "    ('model', RandomForestRegressor(random_state=42))  # Random Forest Regressor\n",
        "])\n",
        "\n",
        "# Train the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "print(f\"Training Performance:\\nMean Squared Error: {mse_train:.4f}\\nR^2 Score: {r2_train:.4f}\")\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "print(f\"\\nTesting Performance:\\nMean Squared Error: {mse_test:.4f}\\nR^2 Score: {r2_test:.4f}\")\n",
        "\n",
        "# Save the pipeline for future use\n",
        "pipeline_path = 'random_forest_pipeline.pkl'\n",
        "joblib.dump(pipeline, pipeline_path)\n",
        "print(f\"\\nPipeline saved to {pipeline_path}\")\n",
        "\n",
        "# (Optional) Feature Importance\n",
        "feature_importances = pipeline.named_steps['model'].feature_importances_\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "print(feature_importance_df)\n"
      ],
      "metadata": {
        "id": "Z5CtLg_ofSVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}